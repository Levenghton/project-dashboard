import streamlit as st
import pandas as pd
import boto3
import json
import os
from datetime import datetime, timedelta
from pathlib import Path
import logging
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('gift-dashboard')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title='–ü–æ–¥–∞—Ä–æ—á–Ω—ã–π –¥–∞—à–±–æ—Ä–¥',
    page_icon='üéÅ',
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title('üéÅ –ü–æ–¥–∞—Ä–æ—á–Ω—ã–π –¥–∞—à–±–æ—Ä–¥')
st.markdown('–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏–∑ AWS S3 (–Ω–∞—á–∏–Ω–∞—è —Å 9 –∞–ø—Ä–µ–ª—è 2025)')

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
if 'data' not in st.session_state:
    st.session_state['data'] = None
if 'combined_df' not in st.session_state:
    st.session_state['combined_df'] = None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è AWS –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤ Streamlit –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞
def get_aws_settings():
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–µ–∫—Ä–µ—Ç–æ–≤ –≤ Streamlit Cloud
    if 'aws' in st.secrets:
        aws_access_key = st.secrets['aws']['aws_access_key']
        aws_secret_key = st.secrets['aws']['aws_secret_key']
        bucket_name = st.secrets['aws'].get('bucket_name', 'technicalgiftagram')
        prefix = st.secrets['aws'].get('prefix', 'processed-logs/funds-log/5min/')
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤, –Ω–æ —Å–∫—Ä—ã–≤–∞–µ–º –∫–ª—é—á–∏
        st.sidebar.text("‚úÖ AWS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ Secrets")
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–µ–∫—Ä–µ—Ç–æ–≤, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        aws_access_key = st.sidebar.text_input('AWS Access Key ID', value='YOUR_ACCESS_KEY', type='password')
        aws_secret_key = st.sidebar.text_input('AWS Secret Access Key', value='YOUR_SECRET_KEY', type='password')
        bucket_name = st.sidebar.text_input('–ò–º—è –±–∞–∫–µ—Ç–∞ S3', value='technicalgiftagram')
        prefix = st.sidebar.text_input('–ü—Ä–µ—Ñ–∏–∫—Å (–ø—É—Ç—å)', value='processed-logs/funds-log/5min/')
    
    return aws_access_key, aws_secret_key, bucket_name, prefix

# –ü–æ–ª—É—á–∞–µ–º AWS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
aws_access_key, aws_secret_key, bucket_name, prefix = get_aws_settings()

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
st.sidebar.header('‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è')

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
def save_settings():
    settings = {
        "aws_access_key": aws_access_key,
        "aws_secret_key": aws_secret_key,
        "bucket_name": bucket_name,
        "prefix": prefix
    }
    
    config_path = Path('streamlit_config.json')
    with open(config_path, 'w') as f:
        json.dump(settings, f, indent=4)
    
    return "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫
@st.cache_data
def load_settings():
    config_path = Path('streamlit_config.json')
    if config_path.exists():
        with open(config_path, 'r') as f:
            settings = json.load(f)
        return settings
    return None

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º –∑–∞–ø—É—Å–∫–µ (–±–µ–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤)
if 'aws' not in st.secrets:
    if st.sidebar.button('–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏'):
        status = save_settings()
        st.sidebar.success(status)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ S3
def connect_to_s3(aws_access_key, aws_secret_key):
    try:
        s3_client = boto3.client(
            's3',
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key
        )
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –ø—É—Ç–µ–º –∑–∞–ø—Ä–æ—Å–∞ —Å–ø–∏—Å–∫–∞ –±–∞–∫–µ—Ç–æ–≤
        s3_client.list_buckets()
        return s3_client, None
    except Exception as e:
        error_message = f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ AWS S3: {str(e)}"
        logger.error(error_message)
        return None, error_message

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∫–µ—Ç–µ
def list_files_in_bucket(s3_client, bucket_name, prefix=''):
    try:
        objects = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
        
        if 'Contents' not in objects:
            return [], f"–û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∫–µ—Ç–µ {bucket_name} —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º {prefix}"
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ñ–∞–π–ª—ã, —á—Ç–æ–±—ã –≤–∫–ª—é—á–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å 2025-04-09 –∏–ª–∏ –ø–æ–∑–∂–µ
        file_list = []
        date_pattern = re.compile(r'(\d{4}-\d{2}-\d{2})')
        
        for obj in objects['Contents']:
            key = obj['Key']
            if key.endswith('.json'):  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .json –∫–∞–∫ –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–µ
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                match = date_pattern.search(key)
                if match:
                    file_date = match.group(1)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞—Ç–∞ –Ω–µ —Ä–∞–Ω—å—à–µ 9 –∞–ø—Ä–µ–ª—è 2025
                    if file_date >= "2025-04-09":
                        file_list.append(key)
        
        return file_list, None
    except Exception as e:
        error_message = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {str(e)}"
        logger.error(error_message)
        return [], error_message

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –∏–∑ S3
@st.cache_data
def load_file_from_s3(_s3_client, bucket_name, file_key):
    try:
        response = _s3_client.get_object(Bucket=bucket_name, Key=file_key)
        file_content = response['Body'].read().decode('utf-8')
        
        # –ü—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å—å —Ñ–∞–π–ª –∫–∞–∫ –æ–¥–∏–Ω JSON
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å—å —Ñ–∞–π–ª –∫–∞–∫ –µ–¥–∏–Ω—ã–π JSON
            json_data = json.loads(file_content)
            logger.info(f"–§–∞–π–ª {file_key} –∑–∞–≥—Ä—É–∂–µ–Ω –∫–∞–∫ –µ–¥–∏–Ω—ã–π JSON")
            return json_data, None
        except json.JSONDecodeError:
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
            logger.info(f"–§–∞–π–ª {file_key} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –µ–¥–∏–Ω—ã–º JSON, –ø—Ä–æ–±—É–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ")
            json_data = []
            for line in file_content.strip().split('\n'):
                if line:
                    try:
                        record = json.loads(line)
                        json_data.append(record)
                    except json.JSONDecodeError:
                        logger.warning(f"–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Å—Ç—Ä–æ–∫—É –∫–∞–∫ JSON: {line}")
            
            if json_data:
                logger.info(f"–§–∞–π–ª {file_key} –∑–∞–≥—Ä—É–∂–µ–Ω –ø–æ—Å—Ç—Ä–æ—á–Ω–æ, –Ω–∞–π–¥–µ–Ω–æ {len(json_data)} –∑–∞–ø–∏—Å–µ–π")
                return json_data, None
            else:
                return None, f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Ñ–∞–π–ª {file_key} –∫–∞–∫ JSON"
    except Exception as e:
        error_message = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {file_key}: {str(e)}"
        logger.error(error_message)
        return None, error_message

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö JSON –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ DataFrame
def process_json_data(json_data, file_name):
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç JSON-–¥–∞–Ω–Ω—ã—Ö
        if isinstance(json_data, list):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ
            if not json_data or len(json_data) == 0:
                return None, "–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
            first_item = json_data[0]
            logger.info(f"–ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –≤ —Ñ–∞–π–ª–µ: {first_item}")
            
            # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç - —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ —Å–ª–æ–≤–∞—Ä—å
            if isinstance(first_item, list):
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä–∏")
                
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
                if len(json_data) > 1:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                    headers = json_data[0]
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä–∏
                    data_dicts = [dict(zip(headers, row)) for row in json_data[1:]]
                    df = pd.DataFrame(data_dicts)
                else:
                    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame
                    return None, "–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö"
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                try:
                    logger.info(f"–ö–ª—é—á–∏ –≤ –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏: {list(first_item.keys())}")
                    df = pd.DataFrame(json_data)
                except (AttributeError, TypeError) as e:
                    # –ï—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–µ —Å–ª–æ–≤–∞—Ä–∏, –ø—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏—Ö
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
                    logger.info(f"–ü—Ä–æ–±—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ –ø—Ä–æ—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
                    
                    # –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å DataFrame —Å –æ–¥–Ω–∏–º —Å—Ç–æ–ª–±—Ü–æ–º
                    df = pd.DataFrame({
                        'Value': json_data,
                        'UserId': range(len(json_data)),  # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID
                        'InvoiceType': 0,  # –ó–∞–≥–ª—É—à–∫–∞
                        'Amount': 0  # –ó–∞–≥–ª—É—à–∫–∞
                    })
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ DataFrame
            logger.info(f"–ö–æ–ª–æ–Ω–∫–∏ –≤ DataFrame: {df.columns.tolist() if not df.empty else '[–ø—É—Å—Ç–æ]'}")
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ —Å TestMode=true
            if 'TestMode' in df.columns:
                df = df[df['TestMode'] != True]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∫ –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏
            df['file_name'] = file_name
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ—ë –≤ —á–∏—Ç–∞–µ–º—É—é –¥–∞—Ç—É
            if 'Timestamp' in df.columns:
                df['Datetime'] = pd.to_datetime(df['Timestamp'], unit='s')
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å —á–∞—Å–æ–º –∏ –¥–Ω–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                df['Hour'] = df['Datetime'].dt.hour
                df['Date'] = df['Datetime'].dt.date
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                date_match = re.search(r'(\d{4}-\d{2}-\d{2})', file_name)
                if date_match:
                    file_date = date_match.group(1)
                    df['Date'] = pd.to_datetime(file_date)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    hour_match = re.search(r'\d{4}-\d{2}-\d{2}-(\d{2})-\d{2}', file_name)
                    hour = int(hour_match.group(1)) if hour_match else 0
                    df['Hour'] = hour
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if 'UserId' not in df.columns:
                df['UserId'] = range(len(df))  # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID
            
            if 'InvoiceType' not in df.columns:
                df['InvoiceType'] = 0  # –ó–∞–≥–ª—É—à–∫–∞
                
            if 'Amount' not in df.columns:
                df['Amount'] = 0  # –ó–∞–≥–ª—É—à–∫–∞
            
            return df, None
        else:
            error_message = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ {file_name}: –î–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–ø–∏—Å–∫–æ–º JSON-–æ–±—ä–µ–∫—Ç–æ–≤"
            logger.error(error_message)
            return None, error_message
    except Exception as e:
        error_message = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ {file_name}: {str(e)}"
        logger.error(error_message)
        return None, error_message

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–Ω—è–º –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
@st.cache_data(ttl=3600)
def prepare_users_daily_data(df):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–æ –¥–Ω—è–º —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    if df is None or df.empty:
        return None
    
    try:
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        df_copy = df.copy()
        if not pd.api.types.is_datetime64_any_dtype(df_copy['Date']):
            df_copy['Date'] = pd.to_datetime(df_copy['Date'])
        
        # –°—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –¥–Ω—è–º
        users_by_day = df_copy.groupby('Date')['UserId'].nunique().reset_index()
        users_by_day.columns = ['Date', '–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏']
        users_by_day = users_by_day.sort_values('Date')
        
        return users_by_day
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º: {str(e)}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–Ω—è–º –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
@st.cache_data(ttl=3600)
def prepare_paying_users_daily_data(df):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–æ –¥–Ω—è–º —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    if df is None or df.empty:
        return None
    
    try:
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        df_copy = df.copy()
        if not pd.api.types.is_datetime64_any_dtype(df_copy['Date']):
            df_copy['Date'] = pd.to_datetime(df_copy['Date'])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ–ø–ª–∞—á–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (InvoiceType = 1)
        paying_df = df_copy[df_copy['InvoiceType'] == 1]
        
        # –°—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –¥–Ω—è–º
        paying_users_by_day = paying_df.groupby('Date')['UserId'].nunique().reset_index()
        paying_users_by_day.columns = ['Date', '–ü–ª–∞—Ç—è—â–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏']
        paying_users_by_day = paying_users_by_day.sort_values('Date')
        
        return paying_users_by_day
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–ª–∞—Ç—è—â–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º: {str(e)}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –ø–æ –Ω–æ–º–µ—Ä—É —Å–ø–∏–Ω–∞
@st.cache_data(ttl=3600)
def calculate_spin_conversion(df):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –Ω–æ–º–µ—Ä—É —Å–ø–∏–Ω–∞"""
    if df is None or df.empty:
        return None
    
    try:
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ–ø–ª–∞—á–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (InvoiceType = 1)
        paying_df = df[df['InvoiceType'] == 1]
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        total_users = df['UserId'].nunique()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∏ —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–ª–∞—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ
        user_payments = paying_df.groupby('UserId').size().reset_index(name='PaymentCount')
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
        conversion_data = []
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Å–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–Ω–∞ (–æ—Ç 1 –¥–æ 10)
        for spin_num in range(1, 11):
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —Å–¥–µ–ª–∞–ª–∏ —Ö–æ—Ç—è –±—ã spin_num –æ–ø–ª–∞—Ç
            users_with_spins = user_payments[user_payments['PaymentCount'] >= spin_num].shape[0]
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
            conversion_rate = (users_with_spins / total_users * 100) if total_users > 0 else 0
            
            conversion_data.append({
                '–ù–æ–º–µ—Ä —Å–ø–∏–Ω–∞': spin_num,
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π': users_with_spins,
                '–ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏–∏': round(conversion_rate, 2)
            })
        
        return pd.DataFrame(conversion_data)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –ø–æ —Å–ø–∏–Ω–∞–º: {str(e)}")
        return None

# –û—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–∑–¥–µ–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.header('üìÇ –î–∞–Ω–Ω—ã–µ –∏–∑ AWS S3')

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ S3 –∏–ª–∏ —Å–±—Ä–æ—Å–∞ –¥–∞–Ω–Ω—ã—Ö
if st.button('–ü–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ AWS –∏ –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ'):
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ session_state
    st.session_state['data'] = None
    st.session_state['combined_df'] = None
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ S3
    with st.spinner('–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ AWS S3...'):
        s3_client, connection_error = connect_to_s3(aws_access_key, aws_secret_key)
    
    if connection_error:
        st.error(connection_error)
    else:
        st.success('–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ AWS S3 —É—Å–ø–µ—à–Ω–æ!')
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        with st.spinner('–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤...'):
            file_list, file_error = list_files_in_bucket(s3_client, bucket_name, prefix)
        
        if file_error:
            st.error(file_error)
        elif not file_list:
            st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∫–µ—Ç–µ {bucket_name} —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º {prefix} –Ω–∞—á–∏–Ω–∞—è —Å 9 –∞–ø—Ä–µ–ª—è 2025")
        else:
            st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(file_list)} —Ñ–∞–π–ª–æ–≤")
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
            all_dataframes = []
            
            for i, file_key in enumerate(file_list):
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                progress = (i + 1) / len(file_list)
                progress_bar.progress(progress)
                status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {i+1} –∏–∑ {len(file_list)}: {file_key}")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
                json_data, load_error = load_file_from_s3(s3_client, bucket_name, file_key)
                
                if load_error:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_key}: {load_error}")
                    continue
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                df, process_error = process_json_data(json_data, file_key)
                
                if process_error:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_key}: {process_error}")
                    continue
                
                if df is not None and not df.empty:
                    all_dataframes.append(df)
            
            # –û—á–∏—â–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ —Å—Ç–∞—Ç—É—Å
            progress_bar.empty()
            status_text.empty()
            
            if not all_dataframes:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤")
            else:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ DataFrame
                combined_df = pd.concat(all_dataframes, ignore_index=True)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–æ–ª–µ–π
                required_fields = ['UserId', 'InvoiceType', 'Amount']
                missing_fields = [field for field in required_fields if field not in combined_df.columns]
                
                if missing_fields:
                    st.error(f"–í –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è: {', '.join(missing_fields)}")
                    st.write("–î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–ª—è –≤ –¥–∞–Ω–Ω—ã—Ö:")
                    st.write(combined_df.columns.tolist())
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    st.write("–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:")
                    st.write(combined_df.head(1).to_dict('records'))
                else:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state
                    st.session_state['data'] = combined_df
                    st.session_state['combined_df'] = combined_df
                    
                    st.success(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {combined_df.shape[0]}")

# –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Ö
if st.session_state['combined_df'] is not None:
    combined_df = st.session_state['combined_df']
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö
    st.subheader('–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö')
    st.dataframe(combined_df.head(10), use_container_width=True)
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    st.subheader('–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏')
    
    col1, col2, col3 = st.columns(3)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–æ–ª–µ–π –ø–µ—Ä–µ–¥ —Ä–∞—Å—á–µ—Ç–æ–º –º–µ—Ç—Ä–∏–∫
    if 'UserId' in combined_df.columns:
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        total_users = combined_df['UserId'].nunique()
        with col1:
            st.metric("–í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", total_users)
    
    if 'UserId' in combined_df.columns and 'InvoiceType' in combined_df.columns:
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        paying_users = combined_df[combined_df['InvoiceType'] == 1]['UserId'].nunique()
        with col2:
            st.metric("–ü–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", paying_users)
    else:
        with col2:
            st.metric('–ü–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π', "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
    
    if 'InvoiceType' in combined_df.columns and 'Amount' in combined_df.columns:
        # –°—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        total_deposits = combined_df[combined_df['InvoiceType'] == 1]['Amount'].sum()
    with col3:
        st.metric('–°—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (—Å—Ç–∞—Ä—Å)', f"{total_deposits:,.2f}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    users_daily_data = prepare_users_daily_data(combined_df)
    paying_users_daily_data = prepare_paying_users_daily_data(combined_df)
    spin_conversion_data = calculate_spin_conversion(combined_df)
    
    # –ì—Ä–∞—Ñ–∏–∫ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    st.subheader('–ì—Ä–∞—Ñ–∏–∫ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –¥–Ω—è–º')
    if users_daily_data is not None and not users_daily_data.empty:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–æ–Ω–∫–µ Date
        if pd.api.types.is_datetime64_any_dtype(users_daily_data['Date']):
            users_daily_data['Date_str'] = users_daily_data['Date'].dt.strftime('%Y-%m-%d')
        else:
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ datetime, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º
            users_daily_data['Date'] = pd.to_datetime(users_daily_data['Date'])
            users_daily_data['Date_str'] = users_daily_data['Date'].dt.strftime('%Y-%m-%d')
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        st.line_chart(users_daily_data.set_index('Date_str')['–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏'])
    else:
        st.info('–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π')
    
    # –ì—Ä–∞—Ñ–∏–∫ –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    st.subheader('–ì—Ä–∞—Ñ–∏–∫ –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –¥–Ω—è–º')
    if paying_users_daily_data is not None and not paying_users_daily_data.empty:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–æ–Ω–∫–µ Date
        if pd.api.types.is_datetime64_any_dtype(paying_users_daily_data['Date']):
            paying_users_daily_data['Date_str'] = paying_users_daily_data['Date'].dt.strftime('%Y-%m-%d')
        else:
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ datetime, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º
            paying_users_daily_data['Date'] = pd.to_datetime(paying_users_daily_data['Date'])
            paying_users_daily_data['Date_str'] = paying_users_daily_data['Date'].dt.strftime('%Y-%m-%d')
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        st.line_chart(paying_users_daily_data.set_index('Date_str')['–ü–ª–∞—Ç—è—â–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏'])
    else:
        st.info('–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π')
    
    # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –ø–æ –Ω–æ–º–µ—Ä—É —Å–ø–∏–Ω–∞
    st.subheader('–ö–æ–Ω–≤–µ—Ä—Å–∏—è –ø–æ –Ω–æ–º–µ—Ä—É —Å–ø–∏–Ω–∞')
    if spin_conversion_data is not None and not spin_conversion_data.empty:
        st.table(spin_conversion_data)
    else:
        st.info('–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –ø–æ —Å–ø–∏–Ω–∞–º')

# –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
st.sidebar.markdown('---')
st.sidebar.info('''
### –û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
–≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, 
–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –Ω–∞–ø—Ä—è–º—É—é –∏–∑ AWS S3.

–î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –Ω–∞—á–∏–Ω–∞—è —Å 9 –∞–ø—Ä–µ–ª—è 2025 –≥–æ–¥–∞.

¬© 2025 –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
''')